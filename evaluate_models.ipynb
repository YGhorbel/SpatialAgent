{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Model Evaluation Notebook (AWS SageMaker S3)\n",
                "This notebook evaluates the **Distance Estimation** and **Inside Prediction** models.\n",
                "It is configured to run on an AWS SageMaker Notebook Instance and load data directly from the S3 bucket: `spatial-agent-data-learner-lab`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Imports\n",
                "import os\n",
                "import json\n",
                "import re\n",
                "import io\n",
                "import numpy as np\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "from torch.utils.data.dataloader import default_collate\n",
                "from torchvision import transforms, models\n",
                "import torchvision.transforms.functional as TF\n",
                "from PIL import Image, ImageFile\n",
                "from tqdm import tqdm\n",
                "import pycocotools.mask as mask_utils\n",
                "import boto3\n",
                "\n",
                "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
                "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
                "print(f\"Using device: {DEVICE}\")\n",
                "\n",
                "# AWS S3 Configuration\n",
                "S3_BUCKET = 'spatial-agent-data-learner-lab'\n",
                "S3_CLIENT = boto3.client('s3')\n",
                "\n",
                "# --- Paths Configuration (Relative to S3 Bucket Root) ---\n",
                "VAL_JSON_KEY = 'val.json'\n",
                "VAL_IMAGE_PREFIX = 'data/val/images'\n",
                "VAL_DEPTH_PREFIX = 'data/val/depths'\n",
                "\n",
                "# Checkpoint Keys in S3\n",
                "DIST_CKPT_S3_KEY_EPOCH5 = 'distance_est/ckpt/epoch_5_iter_6831.pth'\n",
                "DIST_CKPT_S3_KEY_3M = 'distance_est/ckpt/3m_epoch6.pth'\n",
                "INSIDE_CKPT_S3_KEY = 'inside_pred/ckpt/epoch_4.pth'"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Helper Functions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def load_s3_json(bucket, key):\n",
                "    \"\"\"Load JSON file directly from S3.\"\"\"\n",
                "    print(f\"Loading JSON from s3://{bucket}/{key}...\")\n",
                "    response = S3_CLIENT.get_object(Bucket=bucket, Key=key)\n",
                "    content = response['Body'].read().decode('utf-8')\n",
                "    return json.loads(content)\n",
                "\n",
                "def download_s3_checkpoint(bucket, key, local_path):\n",
                "    \"\"\"Download model checkpoint from S3 to local path if not exists.\"\"\"\n",
                "    if not os.path.exists(local_path):\n",
                "        print(f\"Downloading checkpoint s3://{bucket}/{key} to {local_path}...\")\n",
                "        os.makedirs(os.path.dirname(local_path), exist_ok=True)\n",
                "        S3_CLIENT.download_file(bucket, key, local_path)\n",
                "    else:\n",
                "        print(f\"Checkpoint found at {local_path}, skipping download.\")\n",
                "    return local_path\n",
                "\n",
                "def load_s3_image(bucket, key):\n",
                "    \"\"\"Load image directly from S3 as PIL Image.\"\"\"\n",
                "    response = S3_CLIENT.get_object(Bucket=bucket, Key=key)\n",
                "    image_data = response['Body'].read()\n",
                "    return Image.open(io.BytesIO(image_data))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Model Definitions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Distance Model\n",
                "class ResNetDistanceRegressor(nn.Module):\n",
                "    def __init__(self, input_channels=5, backbone='resnet50', pretrained=False):\n",
                "        super().__init__()\n",
                "        self.resnet = getattr(models, backbone)(weights=None)\n",
                "        old_conv = self.resnet.conv1\n",
                "        self.resnet.conv1 = nn.Conv2d(input_channels, old_conv.out_channels,\n",
                "                                      kernel_size=old_conv.kernel_size,\n",
                "                                      stride=old_conv.stride,\n",
                "                                      padding=old_conv.padding,\n",
                "                                      bias=old_conv.bias is not None)\n",
                "        num_feats = self.resnet.fc.in_features\n",
                "        self.resnet.fc = nn.Sequential(\n",
                "            nn.Linear(num_feats, 256),\n",
                "            nn.ReLU(),\n",
                "            nn.Linear(256, 1)\n",
                "        )\n",
                "\n",
                "    def forward(self, x):\n",
                "        return self.resnet(x).squeeze(1)\n",
                "\n",
                "# Inside Model\n",
                "class ResNet50Binary(nn.Module):\n",
                "    def __init__(self, in_channels=5):\n",
                "        super().__init__()\n",
                "        self.resnet = models.resnet50(weights=None)\n",
                "        self.resnet.conv1 = nn.Conv2d(in_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
                "        self.resnet.fc = nn.Linear(self.resnet.fc.in_features, 1)\n",
                "        \n",
                "    def forward(self, x):\n",
                "        x = self.resnet(x)\n",
                "        return x.squeeze(1)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Data Parsing Functions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def replace_masks_with_region(original_question: str) -> str:\n",
                "    original_question = original_question.replace('<image>\\n', '')\n",
                "    token_pattern = re.compile(r'<mask>|[a-zA-Z]+|[^\\s\\w]')\n",
                "    tokens = token_pattern.findall(original_question)\n",
                "    mask_count = 0\n",
                "    modified_tokens = []\n",
                "    for i, token in enumerate(tokens):\n",
                "        if token == '<mask>':\n",
                "            replacement = f\"[Region {mask_count}]\"\n",
                "            mask_count += 1\n",
                "            modified_tokens.append(replacement)\n",
                "        else:\n",
                "            modified_tokens.append(token)\n",
                "    return ' '.join(modified_tokens)\n",
                "\n",
                "def parse_distance_data(data):\n",
                "    print(\"Parsing Distance Data...\")\n",
                "    data = [q for q in data if q['category'] == 'distance']\n",
                "    refined_data = []\n",
                "    \n",
                "    for item in tqdm(data, desc=\"Processing Distance Data\"):\n",
                "        try:\n",
                "            gpt_response = next(conv['value'] for conv in item['conversations'] if conv['from'] == 'gpt')\n",
                "            region_indices = sorted(set(int(x) for x in re.findall(r'\\[Region (\\d+)\\]', gpt_response)))\n",
                "            filtered_rle = [item['rle'][idx] for idx in region_indices if 0 <= idx < len(item['rle'])]\n",
                "            \n",
                "            if len(filtered_rle) == 2:\n",
                "                refined_item = {\n",
                "                    'id': item['id'],\n",
                "                    'image': item['image'],\n",
                "                    'rle': filtered_rle,\n",
                "                    'normalized_answer': item['normalized_answer']\n",
                "                }\n",
                "                refined_data.append(refined_item)\n",
                "        except Exception:\n",
                "            continue\n",
                "    print(f\"Found {len(refined_data)} distance samples.\")\n",
                "    return refined_data\n",
                "\n",
                "def parse_inside_data(data):\n",
                "    print(\"Parsing Inside Data...\")\n",
                "    processed_data = []\n",
                "    potential_items = [item for item in data if len(item['conversations']) > 1 and 'inside' in item['conversations'][1]['value']]\n",
                "    \n",
                "    for item in tqdm(potential_items, desc=\"Processing Inside Data\"):\n",
                "        try:\n",
                "            image = item.get('image')\n",
                "            rle = item.get('rle')\n",
                "            question = item['conversations'][0]['value']\n",
                "            response = item['conversations'][1]['value']\n",
                "            \n",
                "            rephrase_question = replace_masks_with_region(question)\n",
                "            response_split = response.split('.')\n",
                "            sentence_with_inside = [res for res in response_split if 'inside' in res]\n",
                "            \n",
                "            if len(sentence_with_inside) != 1:\n",
                "                continue\n",
                "            \n",
                "            inside_sentence = sentence_with_inside[0]\n",
                "            if 'inside the buffer region' not in inside_sentence:\n",
                "                continue\n",
                "                \n",
                "            before, after = inside_sentence.split('inside the buffer region')\n",
                "            all_ids = re.findall(r'\\[Region (\\d+)\\]', rephrase_question)\n",
                "            before_ids = re.findall(r'\\[Region (\\d+)\\]', before)\n",
                "            after_ids = re.findall(r'\\[Region (\\d+)\\]', after)\n",
                "            \n",
                "            if len(after_ids) != 1 or len(before_ids) == 0:\n",
                "                continue\n",
                "\n",
                "            inside_ids = [int(id) for id in before_ids]\n",
                "            buffer_id = int(after_ids[0])\n",
                "            outside_ids = [int(id) for id in all_ids if int(id) not in inside_ids and int(id) != buffer_id]\n",
                "            \n",
                "            for id in inside_ids:\n",
                "                processed_data.append({\n",
                "                    'image': image,\n",
                "                    'inside': 1,\n",
                "                    'buffer_rle': rle[buffer_id],\n",
                "                    'obj_rle': rle[id]\n",
                "                })\n",
                "            \n",
                "            for id in outside_ids:\n",
                "                processed_data.append({\n",
                "                    'image': image,\n",
                "                    'inside': 0,\n",
                "                    'buffer_rle': rle[buffer_id],\n",
                "                    'obj_rle': rle[id]\n",
                "                })\n",
                "        except Exception:\n",
                "            continue\n",
                "    print(f\"Found {len(processed_data)} inside/outside pairs.\")\n",
                "    return processed_data"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. S3-Aware Dataset Classes with Error Skipping"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class S3DistanceDataset(Dataset):\n",
                "    def __init__(self, samples, bucket, image_prefix, depth_prefix, transform=None, resize=(360, 640)):\n",
                "        self.samples = samples\n",
                "        self.bucket = bucket\n",
                "        self.image_prefix = image_prefix\n",
                "        self.depth_prefix = depth_prefix\n",
                "        self.resize = resize\n",
                "        self.transform = transform\n",
                "\n",
                "    def __len__(self):\n",
                "        return len(self.samples)\n",
                "\n",
                "    def decode_mask(self, rle):\n",
                "        if isinstance(rle['counts'], str):\n",
                "            rle['counts'] = rle['counts'].encode('utf-8')\n",
                "        return mask_utils.decode(rle).astype(np.float32)\n",
                "\n",
                "    def __getitem__(self, idx):\n",
                "        item = self.samples[idx]\n",
                "        components = []\n",
                "\n",
                "        # Load RGB from S3\n",
                "        img_key = f\"{self.image_prefix}/{item['image']}\"\n",
                "        try:\n",
                "            rgb = load_s3_image(self.bucket, img_key).convert('RGB')\n",
                "            rgb = TF.resize(rgb, self.resize)\n",
                "            rgb = np.array(rgb).astype(np.float32) / 255.0\n",
                "            components.append(rgb)\n",
                "        except Exception as e:\n",
                "            # Return None to signal skipping this item\n",
                "            # print(f\"Skipping item {idx}, error loading RGB: {e}\")\n",
                "            return None\n",
                "\n",
                "        # Process Masks (Already in memory)\n",
                "        try:\n",
                "            mask_a = self.decode_mask(item['rle'][0])\n",
                "            mask_b = self.decode_mask(item['rle'][1])\n",
                "            mask_a = Image.fromarray(mask_a)\n",
                "            mask_b = Image.fromarray(mask_b)\n",
                "            \n",
                "            mask_a = TF.resize(mask_a, self.resize, interpolation=transforms.InterpolationMode.NEAREST)\n",
                "            mask_b = TF.resize(mask_b, self.resize, interpolation=transforms.InterpolationMode.NEAREST)\n",
                "            \n",
                "            mask_a = np.array(mask_a).astype(np.float32)\n",
                "            mask_b = np.array(mask_b).astype(np.float32)\n",
                "            \n",
                "            components.append(mask_a[..., None])\n",
                "            components.append(mask_b[..., None])\n",
                "        except Exception as e:\n",
                "            # Return None to signal skipping\n",
                "            print(f\"Skipping item {idx}, error masks: {e}\")\n",
                "            return None\n",
                "\n",
                "        # Input Tensor: 5 Channels\n",
                "        input_tensor = np.concatenate(components, axis=-1)  # H x W x C\n",
                "        input_tensor = torch.tensor(input_tensor).permute(2, 0, 1)  # C x H x W\n",
                "\n",
                "        distance = torch.tensor(item['normalized_answer'], dtype=torch.float32)\n",
                "\n",
                "        if self.transform:\n",
                "            input_tensor = self.transform(input_tensor)\n",
                "\n",
                "        return input_tensor, distance\n",
                "\n",
                "class S3InsideDataset(Dataset):\n",
                "    def __init__(self, samples, bucket, image_prefix, resize=(360, 640)):\n",
                "        self.samples = samples\n",
                "        self.bucket = bucket\n",
                "        self.image_prefix = image_prefix\n",
                "        self.resize = resize\n",
                "        self.to_tensor = transforms.ToTensor()\n",
                "        self.resize_tf = transforms.Resize(resize, interpolation=transforms.InterpolationMode.BILINEAR)\n",
                "\n",
                "    def __len__(self):\n",
                "        return len(self.samples)\n",
                "    \n",
                "    def decode_rle(self, rle):\n",
                "        if isinstance(rle['counts'], str):\n",
                "            rle['counts'] = rle['counts'].encode('utf-8')\n",
                "        return mask_utils.decode(rle).astype(np.float32)\n",
                "    \n",
                "    def __getitem__(self, idx):\n",
                "        item = self.samples[idx]\n",
                "        img_key = f\"{self.image_prefix}/{item['image']}\"\n",
                "        \n",
                "        try:\n",
                "            img = load_s3_image(self.bucket, img_key).convert('RGB')\n",
                "            img = self.resize_tf(img)\n",
                "            img = self.to_tensor(img)\n",
                "            \n",
                "            buffer_mask = self.decode_rle(item['buffer_rle'])\n",
                "            obj_mask = self.decode_rle(item['obj_rle'])\n",
                "\n",
                "            buffer_mask = Image.fromarray((buffer_mask * 255).astype(np.uint8))\n",
                "            buffer_mask = self.resize_tf(buffer_mask)\n",
                "            buffer_mask = self.to_tensor(buffer_mask)\n",
                "\n",
                "            obj_mask = Image.fromarray((obj_mask * 255).astype(np.uint8))\n",
                "            obj_mask = self.resize_tf(obj_mask)\n",
                "            obj_mask = self.to_tensor(obj_mask)\n",
                "            \n",
                "            x = torch.cat([img, buffer_mask, obj_mask], dim=0)\n",
                "            y = torch.tensor(item['inside'], dtype=torch.float32)\n",
                "            \n",
                "            return x, y\n",
                "        except Exception as e:\n",
                "            # Return None to signal skipping\n",
                "            # print(f\"Skipping item {idx}, error: {e}\")\n",
                "            return None\n",
                "\n",
                "# Custom Collate to skip None\n",
                "def collate_skip_none(batch):\n",
                "    batch = list(filter(lambda x: x is not None, batch))\n",
                "    if len(batch) == 0:\n",
                "        return None\n",
                "    return default_collate(batch)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Main Execution\n",
                "1. Load `val.json` from S3.\n",
                "2. Parse data for each task.\n",
                "3. Download checkpoints locally.\n",
                "4. Run evaluation (skipping missing files)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Load Data\n",
                "print(\"Loading Validation Set from S3...\")\n",
                "val_data = load_s3_json(S3_BUCKET, VAL_JSON_KEY)\n",
                "\n",
                "dist_samples = parse_distance_data(val_data)\n",
                "inside_samples = parse_inside_data(val_data)\n",
                "\n",
                "# 2. Prepare Datasets\n",
                "dist_dataset = S3DistanceDataset(dist_samples, S3_BUCKET, VAL_IMAGE_PREFIX, VAL_DEPTH_PREFIX)\n",
                "dist_loader = DataLoader(dist_dataset, batch_size=32, shuffle=False, num_workers=0, collate_fn=collate_skip_none)\n",
                "\n",
                "inside_dataset = S3InsideDataset(inside_samples, S3_BUCKET, VAL_IMAGE_PREFIX)\n",
                "inside_loader = DataLoader(inside_dataset, batch_size=32, shuffle=False, num_workers=0, collate_fn=collate_skip_none)\n",
                "\n",
                "print(\"Datasets ready.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def run_eval_distance(ckpt_s3_key, label):\n",
                "    local_ckpt = f\"/tmp/{os.path.basename(ckpt_s3_key)}\"\n",
                "    download_s3_checkpoint(S3_BUCKET, ckpt_s3_key, local_ckpt)\n",
                "    \n",
                "    model = ResNetDistanceRegressor(input_channels=5, backbone='resnet50')\n",
                "    model.load_state_dict(torch.load(local_ckpt, map_location=DEVICE))\n",
                "    model.to(DEVICE).eval()\n",
                "    \n",
                "    total_abs_error = 0\n",
                "    total_sq_error = 0\n",
                "    count = 0\n",
                "    \n",
                "    with torch.no_grad():\n",
                "        for batch in tqdm(dist_loader, desc=f\"Eval {label}\"):\n",
                "            if batch is None:\n",
                "                continue # Skip empty batch\n",
                "                \n",
                "            inputs, targets = batch\n",
                "            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
                "            preds = model(inputs)\n",
                "            \n",
                "            total_abs_error += torch.abs(preds - targets).sum().item()\n",
                "            total_sq_error += ((preds - targets) ** 2).sum().item()\n",
                "            count += targets.size(0)\n",
                "            \n",
                "    print(f\"\\nResults [{label}]:\")\n",
                "    if count > 0:\n",
                "        print(f\"Evaluated on {count} samples.\")\n",
                "        print(f\"MAE: {total_abs_error/count:.4f} m\")\n",
                "        print(f\"RMSE: {np.sqrt(total_sq_error/count):.4f} m\")\n",
                "    else:\n",
                "        print(\"No valid samples found.\")\n",
                "\n",
                "def run_eval_inside():\n",
                "    local_ckpt = f\"/tmp/{os.path.basename(INSIDE_CKPT_S3_KEY)}\"\n",
                "    download_s3_checkpoint(S3_BUCKET, INSIDE_CKPT_S3_KEY, local_ckpt)\n",
                "    \n",
                "    model = ResNet50Binary(in_channels=5)\n",
                "    model.load_state_dict(torch.load(local_ckpt, map_location=DEVICE))\n",
                "    model.to(DEVICE).eval()\n",
                "    \n",
                "    correct = 0\n",
                "    total = 0\n",
                "    \n",
                "    with torch.no_grad():\n",
                "        for batch in tqdm(inside_loader, desc=\"Eval Inside\"):\n",
                "            if batch is None:\n",
                "                continue # Skip empty batch\n",
                "                \n",
                "            inputs, labels = batch\n",
                "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
                "            preds = (torch.sigmoid(model(inputs)) > 0.5).float()\n",
                "            correct += (preds == labels).sum().item()\n",
                "            total += labels.size(0)\n",
                "            \n",
                "    print(f\"\\nInside Eval Results:\")\n",
                "    if total > 0:\n",
                "        print(f\"Evaluated on {total} samples.\")\n",
                "        print(f\"Inside Acc: {correct/total*100:.2f}%\")\n",
                "    else:\n",
                "        print(\"No valid samples found.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Execute\n",
                "run_eval_distance(DIST_CKPT_S3_KEY_EPOCH5, \"Distance (Epoch 5)\")\n",
                "run_eval_distance(DIST_CKPT_S3_KEY_3M, \"Distance (3m Epoch 6)\")\n",
                "run_eval_inside()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}